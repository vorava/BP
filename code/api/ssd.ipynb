{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CUSTOM_MODEL_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m paths \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mWORKSPACE_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSCRIPTS_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mscripts\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mAPIMODEL_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mANNOTATION_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mIMAGE_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMODEL_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPRETRAINED_MODEL_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mpre-trained-models\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m----> 9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mCHECKPOINT_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m,CUSTOM_MODEL_NAME), \n\u001b[1;32m     10\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mOUTPUT_PATH\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m,CUSTOM_MODEL_NAME, \u001b[39m'\u001b[39m\u001b[39mexport\u001b[39m\u001b[39m'\u001b[39m),  \n\u001b[1;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPROTOC_PATH\u001b[39m\u001b[39m'\u001b[39m:os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprotoc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m  }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CUSTOM_MODEL_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('data', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('data','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('data','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('data', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('data', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('data', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('data', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('data', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('data', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),  \n",
    "    'PROTOC_PATH':os.path.join('data','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CUSTOM_MODEL_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m files \u001b[39m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPIPELINE_CONFIG\u001b[39m\u001b[39m'\u001b[39m:os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mworkspace\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m, CUSTOM_MODEL_NAME, \u001b[39m'\u001b[39m\u001b[39mpipeline.config\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTF_RECORD_SCRIPT\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(paths[\u001b[39m'\u001b[39m\u001b[39mSCRIPTS_PATH\u001b[39m\u001b[39m'\u001b[39m], TF_RECORD_SCRIPT_NAME), \n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mLABELMAP\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(paths[\u001b[39m'\u001b[39m\u001b[39mANNOTATION_PATH\u001b[39m\u001b[39m'\u001b[39m], LABEL_MAP_NAME)\n\u001b[1;32m      5\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CUSTOM_MODEL_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('data', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/vojta/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2023-02-28 21:45:19.616456: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 21:45:19.799394: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/VUTFIT/BP/code/api/data/models/research/object_detection/builders/model_builder_tf2_test.py\", line 21, in <module>\n",
      "    import tensorflow.compat.v1 as tf\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 42, in <module>\n",
      "    from tensorflow.python import data\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/experimental/__init__.py\", line 96, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 22, in <module>\n",
      "    from tensorflow.python.data.experimental.ops import compression_ops\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py\", line 16, in <module>\n",
      "    from tensorflow.python.data.util import structure\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py\", line 22, in <module>\n",
      "    from tensorflow.python.data.util import nest\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 34, in <module>\n",
      "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/framework/sparse_tensor.py\", line 24, in <module>\n",
      "    from tensorflow.python.framework import constant_op\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 25, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/framework/dtypes.py\", line 31, in <module>\n",
      "    from tensorflow.python.types import trace\n",
      "  File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/types/trace.py\", line 30, in <module>\n",
      "    from typing_extensions import Protocol\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1411, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1544, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 147, in _path_stat\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 1\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 4\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"detection\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"data/workspace/annotations/label_map.pbtxt\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"data/workspace/annotations/train.tfrec\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"data/workspace/annotations/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"data/workspace/annotations/val.tfrec\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"data/workspace/annotations/label_map.pbtxt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"data/workspace/annotations/val.tfrec\"\n",
       " }}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 1\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.tfrec')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'val.tfrec')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)      \n",
    "\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python data/models/research/object_detection/model_main_tf2.py --model_dir=data/workspace/models/my_ssd_mobnet --pipeline_config_path=data/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/vojta/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2023-02-25 20:40:59.669961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 20:40:59.984543: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-25 20:41:01.438017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vojta/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/vojta/miniconda3/envs/tf/lib/:/home/vojta/miniconda3/envs/tf/lib/\n",
      "2023-02-25 20:41:01.443182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/vojta/.local/lib/python3.10/site-packages/cv2/../../lib64::/home/vojta/miniconda3/envs/tf/lib/:/home/vojta/miniconda3/envs/tf/lib/\n",
      "2023-02-25 20:41:01.443222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-25 20:41:04.804396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:04.845440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:04.845543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:04.846038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 20:41:04.848488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:04.848580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:04.848627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:05.841532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:05.842199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:05.842250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-25 20:41:05.842411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:05:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 20:41:05.842545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 303 MB memory:  -> device: 0, name: NVIDIA GeForce MX450, pci bus id: 0000:05:00.0, compute capability: 7.5\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0225 20:41:06.197604 140570350380864 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I0225 20:41:06.209205 140570350380864 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0225 20:41:06.209577 140570350380864 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0225 20:41:06.252885 140570350380864 deprecation.py:350] From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['data/workspace/images/train.tfrecord']\n",
      "I0225 20:41:06.305211 140570350380864 dataset_builder.py:162] Reading unweighted datasets: ['data/workspace/images/train.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['data/workspace/images/train.tfrecord']\n",
      "I0225 20:41:06.308764 140570350380864 dataset_builder.py:79] Reading record datasets for input file: ['data/workspace/images/train.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0225 20:41:06.308930 140570350380864 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0225 20:41:06.309005 140570350380864 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0225 20:41:06.326041 140570350380864 deprecation.py:350] From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0225 20:41:06.348588 140570350380864 deprecation.py:350] From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0225 20:41:07.120893 140570350380864 deprecation.py:350] From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0225 20:41:13.223377 140570350380864 deprecation.py:350] From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0225 20:41:16.027809 140570350380864 deprecation.py:350] From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0225 20:41:17.429210 140570350380864 deprecation.py:350] From /home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/vojta/.local/lib/python3.10/site-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "# Load pipeline config and build a detection model\n",
    "#configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "configs = config_util.get_configs_from_pipeline_file(os.path.join('data', 'workspace','models','ssd640', \"pipeline.config\"))\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "#ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-24'))\n",
    "ckpt.restore(os.path.join('data', 'workspace','models','ssd640', 'ckpt-235'))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 16:30:22.372020: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at save_restore_v2_ops.cc:227 : DATA_LOSS: TensorBundle at data/workspace/models/ssd640/ckpt-235 shard 0 (98304 bytes): Checksum does not match: stored 3424403450 vs. calculated on the restored bytes 329430801\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_1932/2280237598.py\", line 21, in detect_fn  *\n        prediction_dict = detection_model.predict(image, shapes)\n    File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 570, in predict  *\n        feature_maps = self._feature_extractor(preprocessed_inputs)\n    File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py\", line 150, in build\n        self.classification_backbone = tf.keras.Model(\n\n    DataLossError: TensorBundle at data/workspace/models/ssd640/ckpt-235 shard 0 (98304 bytes): Checksum does not match: stored 3424403450 vs. calculated on the restored bytes 329430801 [Op:RestoreV2]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m image_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img)\n\u001b[1;32m     12\u001b[0m input_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(np\u001b[39m.\u001b[39mexpand_dims(image_np, \u001b[39m0\u001b[39m), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 13\u001b[0m detections \u001b[39m=\u001b[39m detect_fn(input_tensor)\n\u001b[1;32m     16\u001b[0m num_detections \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(detections\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mnum_detections\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     17\u001b[0m detections \u001b[39m=\u001b[39m {key: value[\u001b[39m0\u001b[39m, :num_detections]\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     18\u001b[0m               \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m detections\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1127\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1127\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1128\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mDataLossError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_1932/2280237598.py\", line 21, in detect_fn  *\n        prediction_dict = detection_model.predict(image, shapes)\n    File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 570, in predict  *\n        feature_maps = self._feature_extractor(preprocessed_inputs)\n    File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/vojta/miniconda3/envs/tf/lib/python3.10/site-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py\", line 150, in build\n        self.classification_backbone = tf.keras.Model(\n\n    DataLossError: TensorBundle at data/workspace/models/ssd640/ckpt-235 shard 0 (98304 bytes): Checksum does not match: stored 3424403450 vs. calculated on the restored bytes 329430801 [Op:RestoreV2]\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "category_index = label_map_util.create_category_index_from_labelmap(os.path.join('data', 'workspace','annotations', 'label_map.pbtxt'))\n",
    "#IMAGE_PATH = \"/mnt/c/VUTFIT/BP/code/api/data/workspace/aug/val/images/5924.png\"\n",
    "IMAGE_PATH = \"/mnt/c/VUTFIT/BP/code/data/test2.png\"\n",
    "#IMAGE_PATH = \"/mnt/c/VUTFIT/BP/code/api/data/workspace/aug/train/images/12322.jpg\"\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=100,\n",
    "            min_score_thresh=.3,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "511eb348ae5494b2a73739d09f1d546e6c901d4aeab6146844964a6fced54e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
